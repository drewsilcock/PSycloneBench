\documentclass{article}

\newcommand{\psykal}{{PS}y{KA}l}
\newcommand{\psyclone}{{PS}yclone}

\begin{document}

\title{Would NEMO benefit from using the \psyclone\ system?}

\author{A. R. Porter and R. W. Ford and T. Graham and M. Bell}

\maketitle

\section{Introduction}

This report describes the outcomes of an initial meeting looking at
the possible use of the \psyclone\ code-generation system with the NEMO
ocean model.

Fundamental to the use of \psyclone\ is the \psykal\ (Parallel System,
Kernel, Algorithm) separation of concerns. In this approach a program
is re-structured into three layers; the Algorithm, PSy and Kernel
layers.  The Algorithm and Kernel layers are the responsibility of the
natural scientist while all code related to parallelism is contained
within the PSy layer. Thus the scientist does not need to concern
themselves with optimisation issues, such as loop fusion, redundant
computation in halos, etc. and parallelism issues, such as placement
of directives and halo swap calls. This separation also improves the
readability and modularity of code and thus greatly aids with
maintenance.


The role of \psyclone\ is to generate the PSy layer (and modify the
Algorithm layer). This role is split into two parts: correctness and
performance. The correctness aspect of \psyclone\ is often underplayed
but there are potentially significant maintenance benefits in this
approach. For example, the horizontal iteration space, ji and jj (and
potentially the vertical iteration space), is generated in the PSy
layer which can help avoid indexing errors.

\psyclone\ has been designed from the ground up with performance and
performance portability in mind. Rather than automatically optimising
code, as compilers do, \psyclone\ allows an optimisation expert to
specify a set of optimisations in a script, which it then applies to
the code. The \psykal\ separation of concerns can be considered a
stripping back of many of the optimisations that have been hard coded
into a program and \psyclone\ then allows such optimisations to be
specified in a script via a set of transformations (a recipe of
transformations if you like) to apply to the code. This hopefully
means that there is no (or at least minimal) loss in performance
compared to hand optimised code when using \psyclone.

The advantage of a recipe is that it can be changed, {\bf with no
  change to the science code}. Thus, for example, one recipe could
target MPI and OpenMP using the Intel compiler on a Cray with a
particular configuration of NEMO. Another recipe could target MPI and
OpenACC using the PGI compiler on GPU's for a different NEMO
configuration. One of the problems with performance portability is
that optimisations for one architecture are not necessarily beneficial
for another. It is difficult enough to get different versions of the
same compiler on the same architecture to work well on a complex code
without changes to source code. If such optimisations are hard coded
then it is very difficult to change the code to work well on another
architecture and almost impossible to have performance portability
with a single code base. The situation is even more complex if, as
with NEMO, a single code base supports different model configurations
that may themselves require different optimisations. \psyclone\ aims
to address this problem by keeping the optimisation space fully
separate from the science code.

\psyclone\ is currently being developed as part of the GungHo project
and forms a component of the Dynamo (the prototype dynamical core)
build system. \psyclone\ can currently generate correct sequential code
for Dynamo and supports transformations such as loop colouring, loop
fusion, OpenMP and module inlining. We are currently working
on OpenACC transformations and are about to start work on MPI support.

Dynamo uses Finite Elements on a grid that is formally
unstructured in the horizontal but structured in the vertical.  In
contrast, NEMO uses Finite Difference on a (tri-polar) regular,
latitude-longitude grid.

In the GOcean2D project we investigated the use of the \psykal\ and
\psyclone\ approach for models using a finite-difference scheme on a
regular lat-lon grid. For this work we took two different
shallow-water models, one of which was the 2D, free-surface component
of NEMO. After restructuring these programs according to the
\psykal\ separation of concerns we were able to show that the
performance of the original code could be recovered with optimisations
restricted to the PSy layer. We also demonstrated that this code could
run efficiently on multi-core architectures using OpenMP directives
and GPU architectures using OpenACC, again with optimisations
restricted to the PSy layer.

The question now is, would this approach be valuable and applicable
for the full NEMO code?  Key to this is the fact that the full NEMO
code is a combination of both 3D and 2D components and thus we have to
decide how the loop over levels (the ``k-loop'') might fit within the
\psyclone\ framework. In Dynamo this loop over levels is not managed by
\psyclone\ but instead is performed within each kernel as a way of
amortising the cost of the indirection associated with the
unstructured mesh.

We believe that there are three possible places in which to locate the
k loop in NEMO:

\begin{enumerate}

\item the Algorithm Layer;

\item the PSy Layer (i.e. make it part of the iteration space managed
  by \psyclone);

\item the Kernel Layer.

\end{enumerate}

NEMO currently uses an $(i,j,k)$ array-index ordering and on current
(CPU-based) architectures reaches a strong-scaling limit when the MPI
sub-domains are about $40\times 40$ grid points. In contrast, the
number of vertical levels in current configurations is typically
$\sim75$. In addition it is likely that the majority of loops over
levels in NEMO are parallelisable. It is therefore highly desirable to
be able to exploit this and this lends weight to option (2). In order
for the PSy layer to manage the iteration space in k it must be
possible to formulate a complete set of rules for the different types
of k loops in the whole of NEMO. For instance, it must be possible to
infer the value of the lower bound of the k-loop around a given kernel
from a knowledge of the grid-point type of the field being updated by
a kernel (plus other meta-data describing the kernel). The number of
exceptions to this must be small if an effective Domain Specific
Language is to be developed for \psyclone's application to NEMO.

However, NEMO has had several decades of development and optimisation
and has thus evolved to make optimal use of the data layout associated
with the $i,j,k$ index ordering. As a consequence there are many
examples where a loop over levels itself contains several, individual
$i,j$ loop nests, e.g.:

\begin{verbatim}
DO jk = 2, jpkm1
   ! Kernel 1
   DO jj = 2, jpjm1
      DO ji = 2, jpim1
         fldb(ji,jj,jk) = ...
      END DO
   END DO
   ! Kernel 2
   DO jj = 2, jpjm1
      DO ji = 2, jpim1
         fldc(ji,jj,jk) = ...
      END DO
   END DO
END DO
\end{verbatim}

This structure favours option (1) since it naturally follows that the
resulting algorithm code would look something like:

\begin{verbatim}
DO jk = 2, jpkm1
   call invoke( kernel1(flda, fldb), &
                kernel2(fldb, fldc) )
END DO
\end{verbatim}

However, a key part of \psykal\ is that the Algorithm layer operates on
logically global fields. In other words it has no concept that the
fields may be domain decomposed (as would be done in an MPI
implementation). This is handled in the PSy layer where any necessary
halo swaps are performed. Unfortunately, the implication of the above
code structure is then that any halo swaps required in the invoke
would be performed separately for \emph{every level} of the
model. This would introduce an unacceptable overhead and we are
therefore forced to rule out option (1).

Finally, there remains option (3) in which the loop over levels is the
responsibility of a kernel. Although this is the approach taken in
Dynamo, the fact that NEMO uses an $i,j,k$ index ordering precludes it
here. This is because, by design, the PSy layer already manages the
loops over i and j and therefore a loop over k within the kernel would
become the innermost loop. The resulting array accesses would have a
stride of $jpi*jpj$ resulting in extremely poor cache use and no SIMD
vectorisation.

We believe therefore that the least intrusive and most performant way
to introduce \psyclone\ to NEMO would be option (2). This is dependent
on it being possible to construct a formal description of the majority
of k loops (i.e. the values to use for the loop bounds) within NEMO.

\section{NEMO Performance/Maintenance Issues that \psyclone\ Could Help With}

This section contains a list of those issues that have been
highlighted at various NEMO HPC and HPC subgroup meetings that
\psyclone\ and the PSyKAl separation of concerns will help to address:

\begin{enumerate}

\item Removal of unecessary halo swaps - PSyclone only generates calls to
  perform halo swaps when they are necessary for correctness.

\item Ability to experiment with collecting of multiple halo swaps
  
\item Aiding loop vectorisation through compiler directives

\item Cache-blocking of loops to better utilise memory bandwidth

\item Support for OpenACC so that NEMO can run on GPU-based systems

\item Support for OpenMP so that NEMO can run in hybrid OpenMP/MPI mode
  
\end{enumerate}

For invasive and repetitive code changes (such as re-structuring loops
for cache blocking) the PSyclone approach is particularly
valuable. This is because such changes are then implemented as a
PSyclone transformation which only affects the generated code - the
oceanographer does not have to worry about the resulting code
complexity (potentially a nested loop with depth six). Tuning of the
cache blocking itself can also be easily done by an HPC expert since
the PSyclone tool would apply any changes to the whole code base.

\section{Incremental introduction of \psyclone\ to NEMO}

One of the key advantages of the \psyclone\ system is that it is
possible for it to co-exist with existing code structures including
infrastructure that makes use of MPI.

As a first step, a section of code must be re-worked to have the
\psykal\ structure. In the context of NEMO, a routine such as
ldf\_slp\_triad could be tackled. The rules that must be followed when
re-structuring the code are:
\begin{itemize}
\item All computation on field values must be performed in kernels;
\item It must be possible to execute any given kernel in parallel but
  a kernel itself must contain no code relating to parallelism
  (e.g. no MPI or OpenMP);
\item All loops over $i$, $j$ and $k$ must be performed in the PSy
  layer;
\item The Algorithm layer must also contain no code relating to
  parallelism.
\end{itemize}
Initially the PSy layer may be written manually. This will then
subsequently be used to inform the development of \psyclone\ to support
NEMO.

\subsection{An example: ldf\_slp}

As an example, we have manually re-structured the {\it ldf\_slp}
routine following the \psykal\ separation of concerns. The resulting
code is too long to include here but may be obtained from the GOcean
SVN repository on puma:
\begin{verbatim}
> svn list https://puma.nerc.ac.uk/svn/GOcean_svn/GOcean/trunk/\
docs/NEMO/example
horizontal_density_gradient_u_mod.f90
horizontal_density_gradient_v_mod.f90
ldf_slp_alg.f90
ldf_slp_alg_processed.f90
ldfslp.F90
psy.f90
\end{verbatim}

Here, ldfslp.F90 is the original routine, ldf\_slp\_alg.f90 is the
Algorithm layer, psy.f90 contains the (manually written) PSy layer and
the horizontal\_density\_$\ast$.f90 files contain kernels.
ldf\_slp\_alg\_processed.f90 contains the Algorithm layer as it would
appear after processing by \psyclone.

Note that this example has only been produced to inform this
document. We make no claim that the meta-data etc. is correct or
sufficient for NEMO.
 
\section{Risks}

Although initial discussions and a code walk through indicate that the
\psykal/\psyclone\ approach could be both beneficial and effective for
NEMO there remain risks. We discuss those here.

\subsection{Tri-diagonal Solves}

If \psyclone\ is to control the iteration space in $k$ as well as in $i,
j$ then this assumes that that space is parallelisable. A clear
exception to this is those routines that perform an implicit solve in
the vertical dimension (e.g. tra\_zdf\_imp). This results in the need
to solve a problem with tri-diagonal form. Kernel meta-data will be
required to identify such cases. Once \psyclone\ is able to identify
such kernels we can envisage it generating calls to optimised solver
routines.

\subsection{OBS}

The OBS (Observation) component of NEMO allows prognostic fields to be
extracted from the model at user-specified geographical locations.  It
is possible that the looping structure within these routines might be
difficult to classify in a way that is suitable for treatment with
\psyclone.

\subsection{AGRIF}

AGRIF (Adaptive Grid Refinement In Fortran) gives NEMO the ability to
run with two-way nesting of higher-resolution meshes. This is achieved
through a pre-processing step in which the tool changes the NEMO
source. In the resulting code field objects (Fortran derived types)
are passed down from the AGRIF infrastructure into wrappers for the
original NEMO routines.

Since \psyclone\ too works by reading and modifying/generating Fortran
source files it is obviously questionable whether it could safely
inter-operate with AGRIF. However, once \psyclone\ has generated the PSy
layer and re-written the Algorithm layer the resulting source code is
standard Fortran. Since AGRIF directives
(e.g. !\$AGRIF\_DO\_NOT\_TREAT) are comments they will remain unchanged
in both the Algorithm and the Kernels.

The most significant issue is then probably the underlying
infrastructure.  Both AGRIF and \psyclone\ normally work with their own
definitions of field objects rather than raw Fortran arrays. Although
this is not essential for \psyclone\ per se (the GOcean 0.1 API for
instance does not use these field objects) it does present problems
for its support of MPI. This is because \psyclone\ requires some way of
keeping track of whether a field's halos are `clean' or `dirty' and it
is natural to encapsulate this within a field object. It is however
possible to envisage other ways of doing this, e.g. by using the ISO
Fortran-C interface to get the address of a Fortran array in memory
and then using this to index into some internal data structure.

\subsection{CPP Keys}

NEMO currently makes use of CPP keys to configure the code at compile
time. Options include e.g. whether to include MPI support and which
ice model to use. It is likely that \psyclone\ can safely be applied to
the code after this pre-processing stage but this must be tested.

\subsection{Run-time Switches}

In common with most simulation packages, NEMO makes use of run-time
flags in order to enable and disable certain functionality. This
becomes an issue for PSyclone when this functionality relates to
choices in the specific Algorithm that is run. As an example, the
ldf\_slp routine contains code that is only required if partial steps
are in use:

\begin{verbatim}
DO jk = 1, jpk             !==   i- & j-gradient of density   ==!
   DO jj = 1, jpjm1
      DO ji = 1, fs_jpim1   ! vector opt.
         zgru(ji,jj,jk) = umask(ji,jj,jk) * ( ... )
      END DO
   END DO
END DO
IF( ln_zps ) THEN    ! partial steps correction at  bottom ocean level
   DO jj = 1, jpjm1
      DO ji = 1, jpim1
         zgru(ji,jj,mbku(ji,jj)) = ...
      END DO
   END DO
ENDIF
!
zdzr(:,:,1) = 0._wp  !== Local vertical density gradient at T-point == !
DO jk = 2, jpkm1
   zdzr(:,:,jk) = ...
END DO
\end{verbatim}

As PSyclone currently has no support for control-flow statements
within an Invoke, the Algorithm Layer for this example would have to
contain three separate Invokes and might look something like:

\begin{verbatim}
CALL invoke( density_igradient(...), &
             density_jgradient(...) )
IF( ln_zps ) THEN
   CALL invoke( partial_steps_correction(...) )
END IF
CALL invoke( local_density_kgradient(...) )
\end{verbatim}

Since optimisation can only be performed within an Invoke, this
structure might result in less performant code. If this proved to be
the case then one might consider re-writing the Algorithm as:

\begin{verbatim}
IF( ln_zps ) THEN
   CALL invoke( density_igradient(...),        &
                density_jgradient(...),        &
                partial_steps_correction(...), &
                local_density_kgradient(...) )
ELSE
   CALL invoke( density_igradient(...),        &
                density_jgradient(...),        &
                local_density_kgradient(...) )
END IF
\end{verbatim}

This issue is not NEMO specific and in fact is currently under
discussion within the GungHo project. Any solution developed there
will be immediately applicable to NEMO.

\subsection{Tracers}

Although the core of NEMO contains only two active tracers
(Temperature and Salinity) it can be used with biogeochemical
models. In those configurations there can be of order $\sim 50$ tracer
species. Although these can be treated independently within the
advection routines there are interactions between them in the
biological routines. This has significant implications for both data
structures and our ability to exploit the additional parallelism that
is available. For the latter we would need additional meta-data to
describe this parallelism and, crucially, indicate when it is not
available.

\section{Index Re-ordering}

\psyclone\ does not directly support the idea of re-ordering NEMO's data
layout. This question has been asked of \psyclone\ before as it is
thought that $i,j,k$ may work best on some architectures and $k,i,j$ on
others. However, the separation of science code and optimisations and
parallelism combined with the separation of the $i,j,k$ looping
structure from the Kernel science code should make it much more
tractable to manually evaluate the benefits of data reordering. In
future work we would be interested in exploring the possibility of
supporting data re-ordering within \psyclone\ in cases where the PSy
layer controls the full iteration space.

\section{Suggested Workplan - 1 Week}

In this section we consider what might be accomplished by two people
with the required skills working intensively with NEMO and \psyclone\
over the course of one week. The aim here would be to address some of
the risks identified in the previous section. We emphasise that there
is no need for \psyclone\ to be able to generate code for NEMO at this
stage; all that is required is a manual implementation of the
\psykal\ separation of concerns for at least one routine. For the
purposes of testing with AGRIF this routine need not be complex.

The tasks that might be tackled are:
\begin{enumerate}

\item Begin with a working AGRIF configuration. Manually 
 re-structure one routine following \psykal\ rules (1 day).

\item Attempt to process the resulting code with AGRIF and 
 document issues (1+ days).

\item Dependent on time remaining after the first two tasks, identify
  those routines that have complex structure in the k loop and attempt
  to classify/manually re-structure them (1 day).

\item If time allows, examine the use of tracers within NEMO and how
  this might be supported by \psyclone\ infrastructure.

\end{enumerate}
The first two tasks require a person with both experience of NEMO and
AGRIF with perhaps some additional support on \psykal\ concepts.  The
latter tasks call for someone familiar with \psykal\ and \psyclone\
concepts, with input from a NEMO expert.

\section{Suggested Workplan - 1 Year}

NEMO is a relatively large and complex code with an extensive user
community. Introducing \psykal/\psyclone\ to such a code base is not to
be undertaken lightly and therefore we suggest an initial project of
one year duration that would enable a thorough investigation of all
the issues. The primary aims of such a project would be: to establish
that the use of \psyclone\ with NEMO (including AGRIF) is technically
feasible; that the natural scientists are happy with the resulting
code and that it performs at least as well as the original.

In this section we present a possible work plan that could be followed
should funding be available for one FTE for one year.

\subsection{WP1: Identify Target NEMO Configurations}
\label{wp1_target_configs}

NEMO supports a wide variety of model configurations and these
influence which source code is physically executed. It is therefore
very important to choose representative configurations that will be
used as the basis for the work. At least one of these configurations
must use AGRIF and another must make significant use of tracers.  Any
other key technologies (e.g. coupling to sea ice) must be covered by
the chosen set of configurations.

Ideally there should be a test suite that covers these configurations
so that the physical correctness of the output of any developed code
can be verified. It is possible that SETTE will fulfil this
requirement.

\subsection{WP2: Classify the Types of Iteration Space}
\label{wp2_classify}

As described earlier, for \psyclone\ to be useful it must be possible to
classify the types of loop structure in the vast majority of the NEMO
code base. The routines involved in the selected configurations must
therefore be identified (e.g. by performing tracing experiments with a
tool such as Tau). The loop structures in these routines must then be
examined. A strategy for supporting those routines that cannot be put
into \psykal\ form must be developed.

As a part of this package we will develop the extensions to the GOcean
1.0 Kernel meta-data that are required to support the
three-dimensional finite-difference scheme used in NEMO.

\subsection{WP3: Infrastructure Support}
\label{wp3_infrastructure}

\psyclone\ must interface to some sort of infrastructure that provides
support for manipulating fields - e.g. creating them and performing
halo swaps. Obviously NEMO already contains support for performing
domain decomposition and MPI operations. Any incremental introduction
of \psyclone\ must therefore work within this framework.

In the latest versions of GOcean and Dynamo the infrastructure is
built around the concept of field objects. While these have benefits,
such an approach would be a significant change to NEMO and may also
conflict with the use of AGRIF. In the initial stages of this work it
will therefore probably be necessary for the infrastructure to work
with fields as Fortran arrays rather than derived types.

The NEMO source code is under almost constant scientific
development. This must be allowed for in any strategy to introduce
\psyclone.

\subsection{WP4: Tracer Support}
\label{wp4_tracers}

As biogeochemical models are of increasing importance we must consider
how best to support them in any \psykal\ version of NEMO. This
includes data structures, infrastructure support and Kernel meta-data.

\subsection{WP5: Performance}
\label{wp5_perf}

Performance is a key issue for NEMO and is one of the reasons for
considering \psyclone\ -- the resulting code will no longer be
restricted to one particular architecture. However, a key first step
is to ensure that the introduction of the \psykal\ separation of
concerns does not harm performance on current machines. Or, if it
does, then that performance can be recovered through code
transformations. We have shown that this is the case for two
shallow-water models~\cite{psykal_shallow} but this work must be
extended for the 3D parts of NEMO. Benchmarking of the configurations
chosen in WP1 will inform the key routines used to examine this
issue. Note that this benchmarking must be performed on processor
counts typical of those used in production runs.

\subsection{WP6: \psyclone\ support}
\label{wp6_autogen}

\psyclone\ already contains some support for finite difference in two
dimensions.  (One of the codes developed as part of the GOcean project
is based upon the free-surface component of NEMO.) It is therefore
natural to first introduce \psyclone\ code-generation to those parts of NEMO
that are two dimensional.

While initial experiments may be performed by manually running
\psyclone\ on individual NEMO routines, this process must ultimately be
made a part of the standard build system. Part of this build system
involves running the C pre-processor (CPP) over the source since some
NEMO functionality (e.g. which ice model to use) is chosen at compile
time through CPP keys. We plan to introduce the \psyclone\
code-generation step after this pre-processing but before AGRIF
transforms the source.

Once \psyclone\ is incorporated into the NEMO build system, the next
stage is to extend the \psyclone\ API to support 3D parts of NEMO.  This
will require the Kernel meta-data and rules developed under Work
Package 2.

\begin{thebibliography}{1}

\bibitem{psykal_shallow} A.~R.~Porter, R.~W.~Ford, M.~Ashworth, G.~D.~Riley and M.~Modani, ``Towards Compiler-Agnostic Performance in Finite-Difference Codes'', to appear in the Proceedings of ParCo 2015.

\end{thebibliography}

\end{document}
